{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "##  Unit Testing for Telecommunication Billing Data Pipeline WK 11 ~ JKoruda"
      ],
      "metadata": {
        "id": "DbhKOGKhxJkK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Background Information\n",
        "You are working on a project related to telecommunication billing data. As part of the project, a\n",
        "data pipeline has been provided to you. The data pipeline is responsible for extracting data from\n",
        "a CSV file, performing transformations using pandas, and storing the transformed data in\n",
        "another CSV file. Your task is to write unit tests for the functions in the data pipeline using the\n",
        "unittest framework"
      ],
      "metadata": {
        "id": "r0kpzSw5wuby"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Guidelines\n",
        "* Use the unittest framework to create test cases for each function in the data\n",
        "pipeline.\n",
        "* Write at least three test cases for each function, covering different scenarios and edge\n",
        "cases.\n",
        "* Ensure that your tests are independent and do not rely on each other.\n",
        "* Name your test methods descriptively to indicate the scenario being tested.\n",
        "* Use assertions to validate the expected behavior of each function.\n",
        "* Provide informative error messages when assertions fail to aid in debugging.\n"
      ],
      "metadata": {
        "id": "jdhgu8Eaw3dZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset composition\n",
        ". It contains telecommunication billing data with the following columns:\n",
        "* customer_id\n",
        "* billing_amount\n",
        "* tax_amount\n",
        "\n",
        "You can use this file as the input for your unit tests.\n",
        "* file > billing_data.csv"
      ],
      "metadata": {
        "id": "XZ7uF4sBxI4y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import panda and test libraries"
      ],
      "metadata": {
        "id": "gp4dCyKtz6Ah"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import unittest\n"
      ],
      "metadata": {
        "id": "5vL0D-MQ0CCK"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Read data from the file"
      ],
      "metadata": {
        "id": "SpoWtOt00Fd6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#file path as defined by file location in colab\n",
        "file_path = '/content/billing_data.csv'\n"
      ],
      "metadata": {
        "id": "6xdRlkhH0UA7"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Extract data loaded from the csv file"
      ],
      "metadata": {
        "id": "a1RpwzlY0Z0r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def data_extraction(file_path):\n",
        "    data = pd.read_csv(file_path)\n",
        "    return data\n"
      ],
      "metadata": {
        "id": "iHxqbvqz0gYM"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tranform data columns"
      ],
      "metadata": {
        "id": "_gNtfPyd1TI5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def data_transformation(data):\n",
        "    data = data.drop_duplicates()\n",
        "    data['billing_amount'] = data['billing_amount'].str.replace('$', '').astype(float)\n",
        "    data['total_charges'] = data['billing_amount'] + data['tax_amount']\n",
        "    return data\n"
      ],
      "metadata": {
        "id": "1NNEQIKz1agS"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load transformed data into output file"
      ],
      "metadata": {
        "id": "jwezzt_x1d_5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#path to output file\n",
        "output_file = '/content/billing_data_output.csv'\n",
        "def data_loading(data, output_file):\n",
        "    data.to_csv(output_file, index=False)"
      ],
      "metadata": {
        "id": "xoL-hu__1pqZ"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Perform test cases on  data extraction, tranformation and Loading procedures"
      ],
      "metadata": {
        "id": "o-so8PZ116dz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pFvW6RJ8g3Qd"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "\n",
        "class TestDataPipeline(unittest.TestCase):\n",
        "\n",
        "#upload data test files\n",
        "    def setUp(self):\n",
        "     self.file_path = 'billing_data.csv'\n",
        "     self.output_file = 'billing_data_output.csv'\n",
        "     self.data = pd.read_csv(self.file_path)\n",
        "\n",
        "#remove files after test\n",
        "    def tearDown(self):\n",
        "      pass\n",
        "\n",
        "    def test_data_extraction(self):\n",
        "        data_extraction(self.file_path)\n",
        "\n",
        "        # Test Data Extraction Function\n",
        "        extracted_data = data_extraction(self.file_path)\n",
        "\n",
        "        #Test if exracted data is a dataframe\n",
        "        self.assertTrue(isinstance(extracted_data, pd.DataFrame))\n",
        "        self.assertEqual(extracted_data.shape, self.data.shape)\n",
        "\n",
        "        # Test the columns of the extracted data\n",
        "        existing_columns = ['customer_id', 'billing_amount', 'tax_amount']\n",
        "        self.assertListEqual(list(extracted_data.columns), existing_columns)\n",
        "\n",
        "        # Test if extraxted data is not empty\n",
        "        self.assertFalse(extracted_data.empty)\n",
        "\n",
        "    def test_data_transformation(self):\n",
        "\n",
        "        extracted_data = data_extraction(self.file_path)\n",
        "\n",
        "        transformed_data = data_transformation(extracted_data)\n",
        "\n",
        "        # test if data transformed is a dataframe\n",
        "        self.assertIsInstance(transformed_data, pd.DataFrame)\n",
        "        self.assertEqual(len(transformed_data), len(self.expected_data))\n",
        "        #check for  duplicates in the data\n",
        "        self.assertEqual(len(transformed_data), len(self.data.drop_duplicates()))\n",
        "\n",
        "        # Test conversion of billing  and tax amount\n",
        "        self.assertTrue(pd.api.types.is_numeric_dtype(transformed_data['tax_amount']))\n",
        "        self.assertTrue(pd.api.types.is_numeric_dtype(transformed_data['billing_amount']))\n",
        "\n",
        "\n",
        "    def test_data_loading(self):\n",
        "\n",
        "       # Test data loadiing in csv\n",
        "        data_loading(self.data, self.output_file)\n",
        "\n",
        "        loaded_data = pd.read_csv(self.output_file)\n",
        "        #validate if loaded_data is dataframe\n",
        "        self.assertTrue(isinstance(loaded_data, pd.DataFrame))\n",
        "        self.assertEqual(loaded_data.shape, self.data.shape)\n",
        "        self.assertTrue(loaded_data.equals(self.data))\n",
        "\n",
        "        # Validate columns of the output files\n",
        "        expected_columns = ['customer_id', 'billing_amount', 'tax_amount', 'total_charges']\n",
        "        self.assertListEqual(list(loaded_data.columns), expected_columns)\n",
        "\n",
        "        # validate  loaded file against original data\n",
        "        self.assertTrue(loaded_data.equals(self.data))\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    unittest.main(argv=['first-arg-is-ignored'], exit=False)"
      ]
    }
  ]
}